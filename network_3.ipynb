{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ase.io import read\n",
    "import matplotlib.pyplot as plt     \n",
    "import matplotlib  # 添加此行以导入 matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from dscribe.descriptors import SOAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "zhfont1=matplotlib.font_manager.FontProperties(fname=r\"SourceHanSansSC-Bold.otf\")\n",
    "# 读取数据\n",
    "with open('supecon.csv', 'r') as file:\n",
    "    data = pd.read_csv(file)\n",
    "    pattern = r'([A-Z][a-z]?)(\\d*)'\n",
    "    elements = data['Formula'].str.findall(pattern).apply(lambda x: [match[0] for match in x])\n",
    "    all_elements = set()\n",
    "    all_elements.update(elements.explode().unique())\n",
    "    all_elements = list(all_elements)\n",
    "\n",
    "    cifs = data['cif']\n",
    "    Tc_AD = data['Tc_AD']  # 目标变量\n",
    "    features = []\n",
    "\n",
    "# 创建标准化器对象\n",
    "scaler = StandardScaler()\n",
    "  # 创建SOAP描述符对象\n",
    "soap = SOAP(\n",
    "    species=all_elements,\n",
    "    r_cut=5,\n",
    "    n_max=1,\n",
    "    l_max=2,\n",
    "    sigma=0.18,\n",
    "    compression={\"mode\": \"off\", \"species_weighting\": None},\n",
    "    sparse=False,\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# 生成SOAP描述符并标准化\n",
    "for i in tqdm(range(len(cifs)), desc=\"读取并用ase解析cif文件,生成SOAP描述符\"):\n",
    "    cif_file = data.loc[i, \"cif\"]\n",
    "    with open('temp_file.cif', 'w') as cif_output:\n",
    "        cif_output.write(cif_file)\n",
    "    atoms = read('temp_file.cif')\n",
    "    soap_descriptors = soap.create(atoms)\n",
    "    soap_descriptors = scaler.fit_transform(np.array(soap_descriptors, dtype=np.float32))\n",
    "    features.append(soap_descriptors)\n",
    "    \n",
    "    labels = np.array(data['Tc_AD'])  # 将标签转换为数组\n",
    "    \n",
    "    # 计算每个描述符的最大长度\n",
    "max_length = max(feature.shape[0] for feature in features)\n",
    "max_width = max(feature.shape[1] for feature in features)\n",
    "\n",
    "# 填充特征\n",
    "padded_features = np.array([np.pad(f, ((0, max_length - f.shape[0]), (0, max_width - f.shape[1])), mode='constant') for f in features])\n",
    "\n",
    "# 将三维数据展平为二维数据\n",
    "padded_features = padded_features.reshape(len(features), -1)  # reshape为(n_samples, n_features)\n",
    "\n",
    "    # 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 确保在填充特征后将 padded_features 转为 NumPy 数组\n",
    "padded_features = np.array([\n",
    "    np.pad(f, ((0, max_length - f.shape[0]),\n",
    "(0, max_width - f.shape[1])), mode='constant') for f in features\n",
    "])\n",
    "\n",
    "# 在分割数据集后，将 X_train 转为 NumPy 数组\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_features, labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "X_train = np.array(X_train)  # 确保 X_train 是 NumPy 数组\n",
    "y_train = np.ravel(y_train)   # 确保 y_train 是一维数组\n",
    "\n",
    "# 打印形状以检查\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# 创建随机森林模型\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# 使用 tqdm 包裹 fit 方法\n",
    "mse_list = []\n",
    "with tqdm(total=1, desc=\"训练进度\") as pbar:\n",
    "     model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 进行预测\n",
    "y_pred_train = model.predict(X_train)  # 可以预测训练集\n",
    "y_pred_test = model.predict(X_test)    # 预测测试集\n",
    "\n",
    "# 计算均方误差\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# 输出均方误差\n",
    "print(f\"训练集均方误差: {mse_train:.4f}\")\n",
    "print(f\"测试集均方误差: {mse_test:.4f}\")\n",
    "\n",
    "# 绘制拟合曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_test, color='yellow', label='预测值')  # 添加预测值的散点图\n",
    "plt.scatter(y_test, y_test, color='blue', label='实际值')  # 添加实际值的散点图\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='理想预测')\n",
    "plt.xlabel('实际 Tc_AD')\n",
    "plt.ylabel('预测 Tc_AD')\n",
    "plt.title('测试集 Tc_AD 预测值与实际值比较')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
